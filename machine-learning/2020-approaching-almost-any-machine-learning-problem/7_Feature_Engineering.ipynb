{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "friendly-direction",
   "metadata": {},
   "source": [
    "# 7 Feature Engineering\n",
    "\n",
    "Before starting this section, we need a little bit more fine grained language about our data points. A dataset consist of data points (instances, samples). Data points consist of a vector of values which are called inputs. Processing these inputs according to some criteria yield features. In short, features are the input values treated and transformed according to our knowledge and priorities.  \n",
    "\n",
    "Feature engineering is basically choosing which data point inputs to use or transform existing inputs into novel features. Other than being numerical values, features have inherent informations that can be interpreted by domain experts or by simple human knowledge like turning dates into various different information such as `dayofweek`, `weekofyear` etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "atlantic-immunology",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1530/3059760647.py:12: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated. Please use Series.dt.isocalendar().week instead.\n",
      "  'weekofyear' : s.dt.weekofyear.values\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'dayofweak': array([0, 0, 0, 1, 1, 2, 2, 2, 3, 3]),\n",
       " 'dayofyear': array([6, 6, 6, 7, 7, 8, 8, 8, 9, 9]),\n",
       " 'hour': array([ 0, 10, 20,  6, 16,  2, 12, 22,  8, 18]),\n",
       " 'is_leap_year': array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True]),\n",
       " 'quarter': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       " 'weekofyear': array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2])}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "s = pd.date_range('2020-01-06', '2020-01-10', freq='10H').to_series()\n",
    "\n",
    "features = {\n",
    "    'dayofweak' : s.dt.dayofweek.values,\n",
    "    'dayofyear' : s.dt.dayofyear.values,\n",
    "    'hour' : s.dt.hour.values,\n",
    "    'is_leap_year' : s.dt.is_leap_year.values,\n",
    "    'quarter' : s.dt.quarter.values,\n",
    "    'weekofyear' : s.dt.weekofyear.values\n",
    "}\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "single-strength",
   "metadata": {},
   "source": [
    "- For a standard column, we wouldn't be able to use `dt` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "extra-teaching",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    datetime\n",
      "0   2012-1-1\n",
      "1   2012-2-1\n",
      "2  2016-12-1\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Can only use .dt accessor with datetimelike values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/onur/companions/aaamlp/7_Feature_Engineering.ipynb Cell 4'\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/onur/companions/aaamlp/7_Feature_Engineering.ipynb#ch0000003?line=2'>3</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(data\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39m2012-1-1\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m2012-2-1\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39m2016-12-1\u001b[39m\u001b[39m'\u001b[39m], columns\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mdatetime\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/onur/companions/aaamlp/7_Feature_Engineering.ipynb#ch0000003?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(df)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/onur/companions/aaamlp/7_Feature_Engineering.ipynb#ch0000003?line=4'>5</a>\u001b[0m df\u001b[39m.\u001b[39;49mdatetime\u001b[39m.\u001b[39;49mdt\u001b[39m.\u001b[39mweekofyear()\n",
      "File \u001b[0;32m~/companions/aaamlp/venv/lib/python3.8/site-packages/pandas/core/generic.py:5583\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   <a href='file:///home/onur/companions/aaamlp/venv/lib/python3.8/site-packages/pandas/core/generic.py?line=5575'>5576</a>\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   <a href='file:///home/onur/companions/aaamlp/venv/lib/python3.8/site-packages/pandas/core/generic.py?line=5576'>5577</a>\u001b[0m     name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_internal_names_set\n\u001b[1;32m   <a href='file:///home/onur/companions/aaamlp/venv/lib/python3.8/site-packages/pandas/core/generic.py?line=5577'>5578</a>\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_metadata\n\u001b[1;32m   <a href='file:///home/onur/companions/aaamlp/venv/lib/python3.8/site-packages/pandas/core/generic.py?line=5578'>5579</a>\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accessors\n\u001b[1;32m   <a href='file:///home/onur/companions/aaamlp/venv/lib/python3.8/site-packages/pandas/core/generic.py?line=5579'>5580</a>\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info_axis\u001b[39m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[1;32m   <a href='file:///home/onur/companions/aaamlp/venv/lib/python3.8/site-packages/pandas/core/generic.py?line=5580'>5581</a>\u001b[0m ):\n\u001b[1;32m   <a href='file:///home/onur/companions/aaamlp/venv/lib/python3.8/site-packages/pandas/core/generic.py?line=5581'>5582</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m[name]\n\u001b[0;32m-> <a href='file:///home/onur/companions/aaamlp/venv/lib/python3.8/site-packages/pandas/core/generic.py?line=5582'>5583</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mobject\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__getattribute__\u001b[39;49m(\u001b[39mself\u001b[39;49m, name)\n",
      "File \u001b[0;32m~/companions/aaamlp/venv/lib/python3.8/site-packages/pandas/core/accessor.py:182\u001b[0m, in \u001b[0;36mCachedAccessor.__get__\u001b[0;34m(self, obj, cls)\u001b[0m\n\u001b[1;32m    <a href='file:///home/onur/companions/aaamlp/venv/lib/python3.8/site-packages/pandas/core/accessor.py?line=178'>179</a>\u001b[0m \u001b[39mif\u001b[39;00m obj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/onur/companions/aaamlp/venv/lib/python3.8/site-packages/pandas/core/accessor.py?line=179'>180</a>\u001b[0m     \u001b[39m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/onur/companions/aaamlp/venv/lib/python3.8/site-packages/pandas/core/accessor.py?line=180'>181</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accessor\n\u001b[0;32m--> <a href='file:///home/onur/companions/aaamlp/venv/lib/python3.8/site-packages/pandas/core/accessor.py?line=181'>182</a>\u001b[0m accessor_obj \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_accessor(obj)\n\u001b[1;32m    <a href='file:///home/onur/companions/aaamlp/venv/lib/python3.8/site-packages/pandas/core/accessor.py?line=182'>183</a>\u001b[0m \u001b[39m# Replace the property with the accessor object. Inspired by:\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/onur/companions/aaamlp/venv/lib/python3.8/site-packages/pandas/core/accessor.py?line=183'>184</a>\u001b[0m \u001b[39m# https://www.pydanny.com/cached-property.html\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/onur/companions/aaamlp/venv/lib/python3.8/site-packages/pandas/core/accessor.py?line=184'>185</a>\u001b[0m \u001b[39m# We need to use object.__setattr__ because we overwrite __setattr__ on\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/onur/companions/aaamlp/venv/lib/python3.8/site-packages/pandas/core/accessor.py?line=185'>186</a>\u001b[0m \u001b[39m# NDFrame\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/onur/companions/aaamlp/venv/lib/python3.8/site-packages/pandas/core/accessor.py?line=186'>187</a>\u001b[0m \u001b[39mobject\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__setattr__\u001b[39m(obj, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name, accessor_obj)\n",
      "File \u001b[0;32m~/companions/aaamlp/venv/lib/python3.8/site-packages/pandas/core/indexes/accessors.py:509\u001b[0m, in \u001b[0;36mCombinedDatetimelikeProperties.__new__\u001b[0;34m(cls, data)\u001b[0m\n\u001b[1;32m    <a href='file:///home/onur/companions/aaamlp/venv/lib/python3.8/site-packages/pandas/core/indexes/accessors.py?line=505'>506</a>\u001b[0m \u001b[39melif\u001b[39;00m is_period_dtype(data\u001b[39m.\u001b[39mdtype):\n\u001b[1;32m    <a href='file:///home/onur/companions/aaamlp/venv/lib/python3.8/site-packages/pandas/core/indexes/accessors.py?line=506'>507</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m PeriodProperties(data, orig)\n\u001b[0;32m--> <a href='file:///home/onur/companions/aaamlp/venv/lib/python3.8/site-packages/pandas/core/indexes/accessors.py?line=508'>509</a>\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCan only use .dt accessor with datetimelike values\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can only use .dt accessor with datetimelike values"
     ]
    }
   ],
   "source": [
    "# Let's use a column without datetime dtype.\n",
    "# it will throw an error\n",
    "df = pd.DataFrame(data=['2012-1-1', '2012-2-1','2016-12-1'], columns=[\"datetime\"])\n",
    "print(df)\n",
    "df.datetime.dt.weekofyear()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intellectual-constitution",
   "metadata": {},
   "source": [
    "Now we will transform `datetime` column into a datetime `dtype`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "olympic-george",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    6\n",
       "1    2\n",
       "2    3\n",
       "Name: datetime, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's use a column with datetime dtype\n",
    "df = pd.DataFrame(data=['2012-1-1', '2012-2-1','2016-12-1'], columns=[\"datetime\"])\n",
    "df[\"datetime\"] = pd.to_datetime(df[\"datetime\"])\n",
    "df.datetime.dt.dayofweek"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handy-robinson",
   "metadata": {},
   "source": [
    "Example `DataFrame` is not given in the repository of the book. So we will write down the values manually and additionally add extra records for the same `customer_id`. First, we start with numpy arrays and show a common pitfall about mixed dataypes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "chubby-terror",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date           datetime64[ns]\n",
      "customer_id            object\n",
      "cat1                   object\n",
      "cat2                   object\n",
      "cat3                   object\n",
      "num1                   object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "columns = ['date', 'customer_id', 'cat1', 'cat2', 'cat3', 'num1']\n",
    "\n",
    "data = np.array([\n",
    "    ['2016-09-01', 146361, 2, 2, 0, 0.518679],\n",
    "    ['2016-09-02', 146361, 3, 2, 1, 4.579128],\n",
    "    ['2017-04-01', 180838, 4, 1, 0, 0.415853],\n",
    "    ['2017-04-06', 180838, 1, 0, 0, 2.815853],\n",
    "    ['2017-08-01', 157857, 3, 3, 1, 2.061687],\n",
    "    ['2017-08-05', 157857, 0, 2, 1, 9.871232],\n",
    "    ['2017-10-01', 157857, 0, 0, 1, 12.061687],\n",
    "    ['2017-12-01', 159772, 5, 1, 1, 0.276558],\n",
    "    ['2017-09-01', 80014, 3, 2, 1, 1.456827]])\n",
    "    \n",
    "df = pd.DataFrame(data=data, columns=columns)\n",
    "\n",
    "# This turns our str type dates into date type\n",
    "df['date'] = pd.to_datetime(df.date)\n",
    "\n",
    "#Checking dtypes of columns\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constant-commission",
   "metadata": {},
   "source": [
    "It's clear from the results that `numpy` turns every column into `object` (which is python string) types such that numerical features like `cat`, `num1`, etc. have also been `str` type. This is important because if we try `agg` method with present `df.num1`, it would throw an error saying no numerical data to aggregate.\n",
    "\n",
    "Now, we try again with a regular list having mixed dataypes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "english-steel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date           datetime64[ns]\n",
       "customer_id             int64\n",
       "cat1                    int64\n",
       "cat2                    int64\n",
       "cat3                    int64\n",
       "num1                  float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['date', 'customer_id', 'cat1', 'cat2', 'cat3', 'num1']\n",
    "\n",
    "data =[\n",
    "    ['2016-09-01', 146361, 2, 2, 0, 0.518679],\n",
    "    ['2016-09-02', 146361, 3, 2, 1, 4.579128],\n",
    "    ['2017-04-01', 180838, 4, 1, 0, 0.415853],\n",
    "    ['2017-04-06', 180838, 1, 0, 0, 2.815853],\n",
    "    ['2017-08-01', 157857, 3, 3, 1, 2.061687],\n",
    "    ['2017-08-05', 157857, 0, 2, 1, 9.871232],\n",
    "    ['2017-10-01', 157857, 0, 0, 1, 12.061687],\n",
    "    ['2017-12-01', 159772, 5, 1, 1, 0.276558],\n",
    "    ['2017-09-01', 80014, 3, 2, 1, 1.456827]]\n",
    "    \n",
    "df = pd.DataFrame(data=data, columns=columns)\n",
    "\n",
    "# This step turns our str type dates into date type\n",
    "df['date'] = pd.to_datetime(df.date)\n",
    "\n",
    "#Checking dtypes of columns\n",
    "df.dtypes\n",
    "# df.to_csv('data/feature_eng.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laden-strap",
   "metadata": {},
   "source": [
    "Finally, everything is either `int` or `float` except datetime column and we can run `agg` method safely on these features.\n",
    "\n",
    "The method `groupby` of pandas returns tuples consisting of the value of column and a `DataFrame` for each item. Now we can create aggregate features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "directed-bacon",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1530/2850402534.py:5: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated. Please use Series.dt.isocalendar().week instead.\n",
      "  df.loc[:, 'weekofyear'] = df['date'].dt.weekofyear\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th colspan=\"2\" halign=\"left\">month</th>\n",
       "      <th colspan=\"2\" halign=\"left\">weekofyear</th>\n",
       "      <th colspan=\"4\" halign=\"left\">num1</th>\n",
       "      <th>customer_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>nunique</th>\n",
       "      <th>mean</th>\n",
       "      <th>nunique</th>\n",
       "      <th>mean</th>\n",
       "      <th>sum</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>nunique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80014</td>\n",
       "      <td>1</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.456827</td>\n",
       "      <td>1.456827</td>\n",
       "      <td>1.456827</td>\n",
       "      <td>1.456827</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>146361</td>\n",
       "      <td>1</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>5.097807</td>\n",
       "      <td>4.579128</td>\n",
       "      <td>0.518679</td>\n",
       "      <td>2.548903</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>157857</td>\n",
       "      <td>2</td>\n",
       "      <td>8.666667</td>\n",
       "      <td>2</td>\n",
       "      <td>33.666667</td>\n",
       "      <td>23.994606</td>\n",
       "      <td>12.061687</td>\n",
       "      <td>2.061687</td>\n",
       "      <td>7.998202</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>159772</td>\n",
       "      <td>1</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.276558</td>\n",
       "      <td>0.276558</td>\n",
       "      <td>0.276558</td>\n",
       "      <td>0.276558</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>180838</td>\n",
       "      <td>1</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>3.231706</td>\n",
       "      <td>2.815853</td>\n",
       "      <td>0.415853</td>\n",
       "      <td>1.615853</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  customer_id   month            weekofyear                  num1             \\\n",
       "              nunique       mean    nunique       mean        sum        max   \n",
       "0       80014       1   9.000000          1  35.000000   1.456827   1.456827   \n",
       "1      146361       1   9.000000          1  35.000000   5.097807   4.579128   \n",
       "2      157857       2   8.666667          2  33.666667  23.994606  12.061687   \n",
       "3      159772       1  12.000000          1  48.000000   0.276558   0.276558   \n",
       "4      180838       1   4.000000          2  13.500000   3.231706   2.815853   \n",
       "\n",
       "                      customer_id  \n",
       "        min      mean     nunique  \n",
       "0  1.456827  1.456827           1  \n",
       "1  0.518679  2.548903           1  \n",
       "2  2.061687  7.998202           1  \n",
       "3  0.276558  0.276558           1  \n",
       "4  0.415853  1.615853           1  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_date_features(df):\n",
    "    \n",
    "#     df = df.copy(deep=True)\n",
    "    df.loc[:,'year'] = df['date'].dt.year\n",
    "    df.loc[:, 'weekofyear'] = df['date'].dt.weekofyear\n",
    "    df.loc[:, 'month'] = df['date'].dt.month\n",
    "    df.loc[:, 'dayofweek'] = df['date'].dt.dayofweek\n",
    "    df.loc[:, 'weekend'] = (df['date'].dt.weekday >= 5).astype(int)\n",
    "    \n",
    "    aggs = {}\n",
    "    aggs['month'] = ['nunique', 'mean']\n",
    "    aggs['weekofyear'] = ['nunique', 'mean']\n",
    "    aggs['num1'] = ['sum', 'max', 'min', 'mean']\n",
    "    aggs['customer_id'] = ['size']\n",
    "    aggs['customer_id'] = ['nunique']\n",
    "    \n",
    "    agg_df = df.groupby('customer_id').agg(aggs)\n",
    "    agg_df = agg_df.reset_index()\n",
    "    return agg_df\n",
    "\n",
    "agg_df = generate_date_features(df)\n",
    "agg_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggregate-lesson",
   "metadata": {},
   "source": [
    "One should note that the original `df`, even though inside a function, is also modified since `DataFrame` is a mutable object and python is a *call by name* language (for further information check this wonderful [talk](https://www.youtube.com/watch?v=_AEJHKGk9ns) and [blog](https://nedbatchelder.com/text/names.html) post by Ned Batchelder). If this is not a desired behavior, first line of `generate_date_features` function should be uncommented.\n",
    "\n",
    "After generating aggregate results, we end up with a `MultiIndex`. In order to flatten this index to change the column values and set the new index as `customer_id`, following code is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "loaded-target",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_df.columns = agg_df.columns.to_flat_index().map(lambda x: '_'.join(x).rstrip('_'))\n",
    "agg_df.set_index('customer_id', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saved-exhibit",
   "metadata": {},
   "source": [
    "We need to match `agg_df` with the original data to merge them. Using the previous trick, we will choose the rows of `agg_df` again and again by indexing it with `df['customer_id']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "rising-vertical",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_df = agg_df.loc[df['customer_id'],:].reset_index()\n",
    "agg_df = agg_df.drop('customer_id', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mighty-pencil",
   "metadata": {},
   "source": [
    "Finally, we merge the both `DataFrame`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "unknown-gibson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>num1</th>\n",
       "      <th>year</th>\n",
       "      <th>weekofyear</th>\n",
       "      <th>month</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>weekend</th>\n",
       "      <th>month_nunique</th>\n",
       "      <th>month_mean</th>\n",
       "      <th>weekofyear_nunique</th>\n",
       "      <th>weekofyear_mean</th>\n",
       "      <th>num1_sum</th>\n",
       "      <th>num1_max</th>\n",
       "      <th>num1_min</th>\n",
       "      <th>num1_mean</th>\n",
       "      <th>customer_id_nunique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>146361</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.518679</td>\n",
       "      <td>2016</td>\n",
       "      <td>35</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>5.097807</td>\n",
       "      <td>4.579128</td>\n",
       "      <td>0.518679</td>\n",
       "      <td>2.548903</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-09-02</td>\n",
       "      <td>146361</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4.579128</td>\n",
       "      <td>2016</td>\n",
       "      <td>35</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>5.097807</td>\n",
       "      <td>4.579128</td>\n",
       "      <td>0.518679</td>\n",
       "      <td>2.548903</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>180838</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.415853</td>\n",
       "      <td>2017</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>3.231706</td>\n",
       "      <td>2.815853</td>\n",
       "      <td>0.415853</td>\n",
       "      <td>1.615853</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-04-06</td>\n",
       "      <td>180838</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.815853</td>\n",
       "      <td>2017</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>3.231706</td>\n",
       "      <td>2.815853</td>\n",
       "      <td>0.415853</td>\n",
       "      <td>1.615853</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-08-01</td>\n",
       "      <td>157857</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2.061687</td>\n",
       "      <td>2017</td>\n",
       "      <td>31</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8.666667</td>\n",
       "      <td>2</td>\n",
       "      <td>33.666667</td>\n",
       "      <td>23.994606</td>\n",
       "      <td>12.061687</td>\n",
       "      <td>2.061687</td>\n",
       "      <td>7.998202</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2017-08-05</td>\n",
       "      <td>157857</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9.871232</td>\n",
       "      <td>2017</td>\n",
       "      <td>31</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8.666667</td>\n",
       "      <td>2</td>\n",
       "      <td>33.666667</td>\n",
       "      <td>23.994606</td>\n",
       "      <td>12.061687</td>\n",
       "      <td>2.061687</td>\n",
       "      <td>7.998202</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2017-10-01</td>\n",
       "      <td>157857</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12.061687</td>\n",
       "      <td>2017</td>\n",
       "      <td>39</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8.666667</td>\n",
       "      <td>2</td>\n",
       "      <td>33.666667</td>\n",
       "      <td>23.994606</td>\n",
       "      <td>12.061687</td>\n",
       "      <td>2.061687</td>\n",
       "      <td>7.998202</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>159772</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.276558</td>\n",
       "      <td>2017</td>\n",
       "      <td>48</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.276558</td>\n",
       "      <td>0.276558</td>\n",
       "      <td>0.276558</td>\n",
       "      <td>0.276558</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>80014</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.456827</td>\n",
       "      <td>2017</td>\n",
       "      <td>35</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.456827</td>\n",
       "      <td>1.456827</td>\n",
       "      <td>1.456827</td>\n",
       "      <td>1.456827</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  customer_id  cat1  cat2  cat3       num1  year  weekofyear  \\\n",
       "0 2016-09-01       146361     2     2     0   0.518679  2016          35   \n",
       "1 2016-09-02       146361     3     2     1   4.579128  2016          35   \n",
       "2 2017-04-01       180838     4     1     0   0.415853  2017          13   \n",
       "3 2017-04-06       180838     1     0     0   2.815853  2017          14   \n",
       "4 2017-08-01       157857     3     3     1   2.061687  2017          31   \n",
       "5 2017-08-05       157857     0     2     1   9.871232  2017          31   \n",
       "6 2017-10-01       157857     0     0     1  12.061687  2017          39   \n",
       "7 2017-12-01       159772     5     1     1   0.276558  2017          48   \n",
       "8 2017-09-01        80014     3     2     1   1.456827  2017          35   \n",
       "\n",
       "   month  dayofweek  weekend  month_nunique  month_mean  weekofyear_nunique  \\\n",
       "0      9          3        0              1    9.000000                   1   \n",
       "1      9          4        0              1    9.000000                   1   \n",
       "2      4          5        1              1    4.000000                   2   \n",
       "3      4          3        0              1    4.000000                   2   \n",
       "4      8          1        0              2    8.666667                   2   \n",
       "5      8          5        1              2    8.666667                   2   \n",
       "6     10          6        1              2    8.666667                   2   \n",
       "7     12          4        0              1   12.000000                   1   \n",
       "8      9          4        0              1    9.000000                   1   \n",
       "\n",
       "   weekofyear_mean   num1_sum   num1_max  num1_min  num1_mean  \\\n",
       "0        35.000000   5.097807   4.579128  0.518679   2.548903   \n",
       "1        35.000000   5.097807   4.579128  0.518679   2.548903   \n",
       "2        13.500000   3.231706   2.815853  0.415853   1.615853   \n",
       "3        13.500000   3.231706   2.815853  0.415853   1.615853   \n",
       "4        33.666667  23.994606  12.061687  2.061687   7.998202   \n",
       "5        33.666667  23.994606  12.061687  2.061687   7.998202   \n",
       "6        33.666667  23.994606  12.061687  2.061687   7.998202   \n",
       "7        48.000000   0.276558   0.276558  0.276558   0.276558   \n",
       "8        35.000000   1.456827   1.456827  1.456827   1.456827   \n",
       "\n",
       "   customer_id_nunique  \n",
       "0                    1  \n",
       "1                    1  \n",
       "2                    1  \n",
       "3                    1  \n",
       "4                    1  \n",
       "5                    1  \n",
       "6                    1  \n",
       "7                    1  \n",
       "8                    1  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df,agg_df], axis=1)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
